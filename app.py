import streamlit as st
import os
import google.generativeai as genai
from dotenv import load_dotenv
from duckduckgo_search import DDGS

# 1. Environment Setup
load_dotenv()

if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
else:
    api_key = os.getenv("GEMINI_API_KEY")

if not api_key:
    st.error("API Key ‡∂ë‡∂ö ‡∑É‡∑ú‡∂∫‡∑è‡∂ú‡∂≠ ‡∂±‡∑ú‡∑Ñ‡∑ê‡∂ö!")
    st.stop()

genai.configure(api_key=api_key)

# 2. Page Config
st.set_page_config(page_title="Kaputa AI", page_icon="üê¶", layout="centered")
st.title("Kaputa AI üê¶")
st.caption("Gemini 2.5 Flash | Context Aware Chat üß†")

# 3. Helper Functions
def search_web(query):
    try:
        results = DDGS().text(query, max_results=3)
        return "\n".join([f"- {r['title']}: {r['body']}" for r in results])
    except:
        return None

# --- SESSION STATE SETUP (History & Memory) ---

# Chat History ‡∂ë‡∂ö ‡∂≠‡∑í‡∂∫‡∑è‡∂ú‡∂±‡∑ä‡∂± ‡∂≠‡∑ê‡∂± (List of Chats)
if "chat_sessions" not in st.session_state:
    st.session_state.chat_sessions = {
        "Chat 1": [] # ‡∂∏‡∑î‡∂Ω‡∑í‡∂±‡∑ä‡∂∏ Chat 1 ‡∂ö‡∑í‡∂∫‡∂Ω‡∑è ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑Ñ‡∂Ø‡∂±‡∑Ä‡∑è
    }

# ‡∂Ø‡∑ê‡∂±‡∂ß Active ‡∑Ä‡∑ô‡∂Ω‡∑è ‡∂≠‡∑í‡∂∫‡∑ô‡∂± Chat ‡∂ë‡∂ö‡∑ö ‡∂±‡∂∏
if "active_chat" not in st.session_state:
    st.session_state.active_chat = "Chat 1"

# Chat ‡∂ú‡∂´‡∂± (‡∂±‡∂∏‡∑ä ‡∑Ñ‡∂Ø‡∂±‡∑ä‡∂±)
if "chat_counter" not in st.session_state:
    st.session_state.chat_counter = 1

# 4. SIDEBAR (History Panel)
with st.sidebar:
    # A. New Chat Button (‡∂ã‡∂©‡∑í‡∂±‡∑ä‡∂∏)
    if st.button("‚ûï New Chat", use_container_width=True, type="primary"):
        st.session_state.chat_counter += 1
        new_chat_name = f"Chat {st.session_state.chat_counter}"
        st.session_state.chat_sessions[new_chat_name] = [] # ‡∂Ö‡∂Ω‡∑î‡∂≠‡∑ä ‡∂Ω‡∑í‡∑É‡∑ä‡∂ß‡∑ä ‡∂ë‡∂ö‡∂ö‡∑ä
        st.session_state.active_chat = new_chat_name # ‡∂Ö‡∂Ω‡∑î‡∂≠‡∑ä ‡∂ë‡∂ö‡∂ß ‡∂∏‡∑è‡∂ª‡∑î ‡∑Ä‡∑ô‡∂±‡∑Ä‡∑è
        st.rerun()
    
    st.markdown("---")
    st.subheader("ÔøΩ History")
    
    # B. Chat History List (‡∂¥‡∂ª‡∂´ Chats ‡∂ß‡∑í‡∂ö ‡∂¥‡∑ô‡∂±‡∑ä‡∑Ä‡∑ì‡∂∏)
    # ‡∂Ö‡∂¥‡∑í Reverse ‡∂ö‡∂ª‡∂±‡∑Ä‡∑è ‡∂Ö‡∂Ω‡∑î‡∂≠‡∑ä ‡∂í‡∑Ä ‡∂ã‡∂©‡∑í‡∂±‡∑ä ‡∂¥‡∑ô‡∂±‡∑ä‡∂±‡∂±‡∑ä‡∂±
    chat_names = list(st.session_state.chat_sessions.keys())[::-1]
    
    selected_chat = st.radio(
        "Go to chat:",
        chat_names,
        index=chat_names.index(st.session_state.active_chat) if st.session_state.active_chat in chat_names else 0,
        label_visibility="collapsed",
        key="history_radio"
    )
    
    # Radio Button ‡∂ë‡∂ö‡∑ô‡∂±‡∑ä Chat ‡∂ë‡∂ö ‡∂∏‡∑è‡∂ª‡∑î ‡∑Ä‡∑î‡∂±‡∑ú‡∂≠‡∑ä
    if selected_chat != st.session_state.active_chat:
        st.session_state.active_chat = selected_chat
        st.rerun()

    st.markdown("---")
    
    # C. Tools
    enable_search = st.toggle("üåç Web Search")
    
    # Clear Current Chat
    if st.button("ÔøΩÔ∏è Clear This Chat"):
        st.session_state.chat_sessions[st.session_state.active_chat] = []
        st.rerun()

# 5. Model Setup
try:
    model = genai.GenerativeModel('gemini-2.5-flash')
except:
    st.error("Model Error")

# 6. MAIN CHAT INTERFACE
st.subheader(f"üí¨ {st.session_state.active_chat}")

# Active Chat ‡∂ë‡∂ö‡∑ö ‡∂∏‡∑ê‡∑É‡∑ö‡∂¢‡∑ä ‡∂ß‡∑í‡∂ö ‡∂ú‡∂±‡∑ä‡∂±
current_messages = st.session_state.chat_sessions[st.session_state.active_chat]

# ‡∂∏‡∑ê‡∑É‡∑ö‡∂¢‡∑ä ‡∂ß‡∑í‡∂ö ‡∂¥‡∑ô‡∂±‡∑ä‡∂±‡∂±‡∑ä‡∂±
for message in current_messages:
    role = "assistant" if message["role"] == "model" else "user"
    with st.chat_message(role):
        st.markdown(message["content"])

# 7. INPUT & LOGIC
prompt = st.chat_input("‡∂Ö‡∑Ñ‡∂±‡∑ä‡∂±...")

if prompt:
    # 1. User Message Save & Display
    st.chat_message("user").markdown(prompt)
    st.session_state.chat_sessions[st.session_state.active_chat].append({"role": "user", "content": prompt})

    # 2. AI Response Generation
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            try:
                # --- CONTEXT AWARENESS LOGIC ---
                # ‡∂∏‡∑ô‡∂≠‡∂±‡∂Ø‡∑ì ‡∂Ö‡∂¥‡∑í 'current_messages' (‡∂¥‡∂ª‡∂´ ‡∂ö‡∂≠‡∑è‡∑Ä) ‡∂î‡∂ö‡∑ä‡∂ö‡∑ú‡∂∏ ‡∂∏‡∑ú‡∂©‡∂Ω‡∑ä ‡∂ë‡∂ö‡∂ß ‡∂∫‡∑Ä‡∂±‡∑Ä‡∑è.
                # ‡∂ë‡∂≠‡∂ö‡∑ú‡∂ß Kaputa ‡∂Ø‡∂±‡∑ä‡∂±‡∑Ä‡∑è ‡∂Ö‡∂¥‡∑í ‡∂ö‡∂Ω‡∑í‡∂±‡∑ä ‡∂ö‡∂≠‡∑è ‡∂ö‡∂ª‡∑ö ‡∂∏‡∑ú‡∂±‡∑Ä‡∂Ø ‡∂ö‡∑í‡∂∫‡∂Ω‡∑è.
                
                history_for_gemini = [
                    {"role": "user", "parts": [m["content"]]} if m["role"] == "user"
                    else {"role": "model", "parts": [m["content"]]}
                    for m in st.session_state.chat_sessions[st.session_state.active_chat]
                ]
                
                # Chat Object ‡∂ë‡∂ö ‡∑Ñ‡∂Ø‡∂±‡∑Ä‡∑è (History ‡∂ë‡∂ö‡∑ä‡∂ö)
                chat = model.start_chat(history=history_for_gemini)
                
                # Search Logic
                if enable_search:
                    search_results = search_web(prompt)
                    if search_results:
                        final_prompt = f"Web Info:\n{search_results}\n\nUser Question: {prompt}"
                        response = chat.send_message(final_prompt)
                    else:
                        response = chat.send_message(prompt)
                else:
                    response = chat.send_message(prompt)
                
                st.markdown(response.text)
                
                # 3. AI Reply Save
                st.session_state.chat_sessions[st.session_state.active_chat].append({"role": "model", "content": response.text})

            except Exception as e:
                st.error(f"Error: {e}")