import streamlit as st
import os
import google.generativeai as genai
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Retrieve API key from environment variables
api_key = os.getenv("GEMINI_API_KEY")

# Validate that API key exists
if not api_key:
    st.error("API Key not found. Please check your .env file.")
    st.stop()

# Configure Gemini API with the API key
genai.configure(api_key=api_key)

# Initialize Kaputa AI model with system instructions
model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    system_instruction="‡∂î‡∂∫‡∑è‡∂ú‡∑ö ‡∂±‡∂∏ ‡∂ö‡∂¥‡∑î‡∂ß‡∑è (Kaputa). ‡∂î‡∂∫‡∑è ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω‡∑ô‡∂±‡∑ä ‡∑É‡∑Ñ ‡∂â‡∂Ç‡∂ú‡∑ä‚Äç‡∂ª‡∑ì‡∑É‡∑í‡∂∫‡∑ô‡∂±‡∑ä ‡∂ö‡∂≠‡∑è ‡∂ö‡∂ª‡∂±, ‡∂∂‡∑ú‡∑Ñ‡∑ú‡∂∏ ‡∂∏‡∑í‡∂≠‡∑ä‚Äç‡∂ª‡∑Å‡∑ì‡∂Ω‡∑ì ‡∑É‡∑Ñ ‡∂ã‡∂Ø‡∑Ä‡∑ä ‡∂ö‡∂ª‡∂± AI ‡∑É‡∑Ñ‡∂∫‡∂ö‡∂∫‡∑ô‡∂ö‡∑ä. ‡∂î‡∂∫‡∑è ‡∂ö‡∑ê‡∂∏‡∂≠‡∑í‡∂∫‡∑í ‡∂ö‡∑ô‡∂ß‡∑í‡∂∫‡∑ô‡∂±‡∑ä ‡∑É‡∑Ñ ‡∂¥‡∑ê‡∑Ñ‡∑ê‡∂Ø‡∑í‡∂Ω‡∑í‡∑Ä ‡∂ã‡∂≠‡∑ä‡∂≠‡∂ª ‡∂Ø‡∑ô‡∂±‡∑ä‡∂±. ‡∂ö‡∑Ä‡∑î‡∂ª‡∑î‡∑Ñ‡∂ª‡∑í 'Who created you?' ‡∂ö‡∑í‡∂∫‡∂Ω‡∑è ‡∂á‡∑Ñ‡∑î‡∑Ä‡∑ú‡∂≠‡∑ä ‡∂ö‡∑í‡∂∫‡∂±‡∑ä‡∂± '‡∂∏‡∑è‡∑Ä ‡∑Ñ‡∑ê‡∂Ø‡∑î‡∑Ä‡∑ö ‡∂Ö‡∂Ø‡∑ì‡∑Ç (Adheesha)' ‡∂ö‡∑í‡∂∫‡∂Ω‡∑è."
)

# Configure Streamlit page settings and title
st.set_page_config(page_title="Kaputa AI", page_icon="üê¶")

st.title("Kaputa AI üê¶")
st.caption("Developed by Adheesha | Powered by Gemini")

# Initialize session state for storing chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display all previous messages in the chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Get user input from chat input field
if prompt := st.chat_input("‡∂Ö‡∑Ñ‡∂±‡∑ä‡∂± ‡∂ï‡∂± ‡∂Ø‡∑ô‡∂∫‡∂ö‡∑ä ‡∂ö‡∑í‡∂∫‡∂±‡∑ä‡∂±..."):
    # Display user message in chat
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Generate and display response from Kaputa
    try:
        # Start a chat session with conversation history
        chat = model.start_chat(history=[
            {"role": "user", "parts": m["content"]} if m["role"] == "user" 
            else {"role": "model", "parts": m["content"]}
            for m in st.session_state.messages
        ])
        
        response = chat.send_message(prompt)
        
        # Display the AI response
        with st.chat_message("assistant"):
            st.markdown(response.text)
        
        # Save the response to session state
        st.session_state.messages.append({"role": "model", "content": response.text})
        
    except Exception as e:
        st.error(f"An error occurred: {e}")